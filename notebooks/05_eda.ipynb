{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada173d2",
   "metadata": {},
   "source": [
    "# Task 2 Extension: LSTM vs. ARIMA Comparison\n",
    "\n",
    "## Objective\n",
    "To satisfy the project requirements, we implement a Deep Learning model (LSTM) and compare its performance against our statistical model (ARIMA).\n",
    "\n",
    "## Methodology\n",
    "1.  **Data Prep:** Scale data to 0-1 range (required for Neural Networks).\n",
    "2.  **Architecture:** 2-layer LSTM with Dropout to prevent overfitting.\n",
    "3.  **Evaluation:** Compare MAE, RMSE, and MAPE between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d868d4f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m sys.path.append(os.path.abspath(os.path.join(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Import the LSTM functions we just wrote\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_lstm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_lstm, predict_lstm\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Make plots big enough to see\u001b[39;00m\n\u001b[32m     16\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33mfigure.figsize\u001b[39m\u001b[33m'\u001b[39m] = (\u001b[32m14\u001b[39m, \u001b[32m7\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/portfolio-optimization/src/model_lstm.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_sequences\u001b[39m(data, seq_length=\u001b[32m60\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Cell 2: Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Add the 'src' directory to the path so we can import our custom code\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "# Import the LSTM functions we just wrote\n",
    "from src.model_lstm import train_lstm, predict_lstm\n",
    "\n",
    "# Make plots big enough to see\n",
    "plt.rcParams['figure.figsize'] = (14, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea782fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load and Prep Data\n",
    "# Load Cleaned Data\n",
    "df = pd.read_csv('../data/processed/cleaned_close_prices.csv', index_col=0, parse_dates=True)\n",
    "tsla = df['TSLA']\n",
    "\n",
    "# Split Data (80% Train, 20% Test) - Must match ARIMA split for fair comparison\n",
    "train_size = int(len(tsla) * 0.8)\n",
    "train, test = tsla[:train_size], tsla[train_size:]\n",
    "\n",
    "print(f\"Train samples: {len(train)}\")\n",
    "print(f\"Test samples: {len(test)}\")\n",
    "\n",
    "# Prepare inputs for prediction\n",
    "# We need the last 60 days of the training data to start predicting the test data\n",
    "dataset_total = pd.concat((train, test), axis=0)\n",
    "inputs = dataset_total[len(dataset_total) - len(test) - 60:]\n",
    "\n",
    "print(\"Data preparation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
